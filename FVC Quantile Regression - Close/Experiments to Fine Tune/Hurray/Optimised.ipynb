{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"sourceType":"competition"},{"sourceId":13905913,"sourceType":"datasetVersion","datasetId":8852072},{"sourceId":662983,"sourceType":"modelInstanceVersion","modelInstanceId":501638,"modelId":516804}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI-Driven Early Prediction of Pulmonary Fibrosis Using Deep Learning\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\nCONFIG = {\n    \"lr\": 2e-3,\n    \"weight_decay\": 3e-5,\n    \"batch_size\": 64,\n    \"epochs\": 300,\n    \"n_folds\": 5,\n    \"quantiles\": [0.2, 0.5, 0.8], \n    \"patience\": 50,\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"data_dir\": \"../input/osic-pulmonary-fibrosis-progression\",\n    \"biomarker_path\": \"../input/feature-extraction-u-net-segmentation/master_dataset.csv\",\n    \"seed\": 42\n}\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(CONFIG['seed'])\n\n# ==========================================\n# STRATEGY C: RATIO-BASED DATA PREPROCESSING\n# ==========================================\ndef preprocess_data_ratio(config):\n    clinical_df = pd.read_csv(f\"{config['data_dir']}/train.csv\")\n    biomarkers_df = pd.read_csv(config['biomarker_path'])\n    \n    image_features = [\n        'lung_vol_ml', 'hu_mean', 'hu_std', 'hu_skew', 'hu_kurt',\n        'glcm_contrast', 'glcm_homogeneity', 'glcm_energy', 'glcm_correlation'\n    ]\n    \n    cols_to_keep = ['Patient'] + [c for c in image_features if c in biomarkers_df.columns]\n    biomarkers_clean = biomarkers_df[cols_to_keep].drop_duplicates(subset=['Patient'])\n    \n    train = clinical_df.merge(biomarkers_clean, on='Patient', how='inner')\n    \n    train['Weeks'] = train['Weeks'].astype(int)\n    train.sort_values(['Patient', 'Weeks'], inplace=True)\n    \n    baseline = train.groupby('Patient').first().reset_index()\n    baseline = baseline[['Patient', 'FVC', 'Percent']].rename(\n        columns={'FVC': 'Base_FVC', 'Percent': 'Base_Percent'}\n    )\n    train = train.merge(baseline, on='Patient', how='left')\n    \n    base_weeks = train.groupby('Patient')['Weeks'].min().reset_index().rename(\n        columns={'Weeks': 'Base_Week'}\n    )\n    train = train.merge(base_weeks, on='Patient', how='left')\n    train['Relative_Weeks'] = train['Weeks'] - train['Base_Week']\n    \n    # Target: FVC Ratio\n    train['FVC_Ratio'] = train['FVC'] / train['Base_FVC']\n    \n    # Interaction features\n    train['FVC_Week_Interaction'] = train['Base_FVC'] * train['Relative_Weeks']\n    train['Age_Week_Interaction'] = train['Age'] * train['Relative_Weeks']\n    \n    available_img_feats = [c for c in image_features if c in train.columns]\n    \n    if 'lung_vol_ml' in train.columns:\n        train['LungVol_FVC_Ratio'] = train['lung_vol_ml'] / (train['Base_FVC'] + 1e-6)\n    \n    scaler = StandardScaler()\n    \n    num_cols = ['Age', 'Base_Percent', 'Relative_Weeks'] + available_img_feats\n    interaction_cols = ['FVC_Week_Interaction', 'Age_Week_Interaction']\n    \n    if 'LungVol_FVC_Ratio' in train.columns:\n        interaction_cols.append('LungVol_FVC_Ratio')\n    \n    all_num_cols = num_cols + interaction_cols\n    train[all_num_cols] = scaler.fit_transform(train[all_num_cols])\n    \n    train['Base_FVC_Raw'] = train['Base_FVC']\n    \n    train['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n    train['Smk_Ex'] = train['SmokingStatus'].apply(lambda x: 1 if x == 'Ex-smoker' else 0)\n    train['Smk_Cur'] = train['SmokingStatus'].apply(lambda x: 1 if x == 'Currently smokes' else 0)\n    \n    feature_cols = all_num_cols + ['Sex', 'Smk_Ex', 'Smk_Cur']\n    \n    ratio_scaler = StandardScaler()\n    ratio_scaler.fit(train[['FVC_Ratio']])\n    train['FVC_Ratio_Scaled'] = ratio_scaler.transform(train[['FVC_Ratio']])\n    \n    print(f\"‚úÖ Preprocessing Complete. Final Shape: {train.shape}\")\n    print(f\"‚úÖ Features Used: {len(feature_cols)}\")\n    \n    return train, feature_cols, ratio_scaler\n\n# ==========================================\n# MODEL\n# ==========================================\nclass EnhancedQuantileMLP(nn.Module):\n    def __init__(self, input_dim, quantiles, dropout=0.25):\n        super().__init__()\n        h1, h2, h3 = 256, 128, 64\n        \n        self.net = nn.Sequential(\n            nn.Linear(input_dim, h1), nn.BatchNorm1d(h1), nn.LeakyReLU(0.1), nn.Dropout(dropout),\n            nn.Linear(h1, h2), nn.BatchNorm1d(h2), nn.LeakyReLU(0.1), nn.Dropout(dropout),\n            nn.Linear(h2, h3), nn.BatchNorm1d(h3), nn.LeakyReLU(0.1), nn.Dropout(dropout),\n            nn.Linear(h3, len(quantiles))\n        )\n    \n    def forward(self, x):\n        return self.net(x)\n\ndef quantile_loss(preds, target, quantiles):\n    losses = []\n    for i, q in enumerate(quantiles):\n        errors = target - preds[:, i].unsqueeze(1)\n        loss = torch.max((q-1) * errors, q * errors)\n        losses.append(loss)\n    return torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n\n# ==========================================\n# METRICS\n# ==========================================\ndef calculate_metrics(y_true_fvc, q_preds_ratio, baseline_fvc):\n    q20 = q_preds_ratio[:, 0] * baseline_fvc\n    q50 = q_preds_ratio[:, 1] * baseline_fvc\n    q80 = q_preds_ratio[:, 2] * baseline_fvc\n    \n    sigma = q80 - q20\n    sigma_clipped = np.maximum(sigma, 70)\n    \n    delta = np.minimum(np.abs(y_true_fvc - q50), 1000)\n    lll = - (np.sqrt(2) * delta / sigma_clipped) - np.log(np.sqrt(2) * sigma_clipped)\n    \n    mse = mean_squared_error(y_true_fvc, q50)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_true_fvc, q50)\n    r2 = r2_score(y_true_fvc, q50)\n    rmae = mae / (np.mean(np.abs(y_true_fvc)) + 1e-6)\n    \n    return {\n        'lll': np.mean(lll),\n        'mse': mse,\n        'rmse': rmse,\n        'mae': mae,\n        'rmae': rmae,\n        'r2': r2\n    }\n\n# ==========================================\n# SIGMA CALIBRATION\n# ==========================================\ndef calibrate_sigma_ratio(ratio_preds, scale_factor=0.85):\n    preds_copy = ratio_preds.copy()\n    q20, q50, q80 = preds_copy[:, 0], preds_copy[:, 1], preds_copy[:, 2]\n    \n    new_q20 = q50 - (q50 - q20) * scale_factor\n    new_q80 = q50 + (q80 - q50) * scale_factor\n    \n    return np.column_stack([new_q20, q50, new_q80])\n\n# ==========================================\n# TRAINING WITH RATIO PREDICTION\n# ==========================================\ndef train_ratio_model():\n    df, features, ratio_scaler = preprocess_data_ratio(CONFIG)\n    patients = df['Patient'].unique()\n    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['seed'])\n    \n    oof_indices = []\n    oof_ratio_preds = []\n    oof_trues_fvc = []\n    oof_baselines = []\n    \n    print(f\"\\nüöÄ Training RATIO PREDICTION Model\")\n    print(f\"üìä Training on {len(df)} visits across {len(patients)} patients\")\n    print(\"=\"*80)\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(patients)):\n        print(f\"\\n{'='*80}\")\n        print(f\"FOLD {fold+1}/{CONFIG['n_folds']}\")\n        print(f\"{'='*80}\")\n        \n        train_p, val_p = patients[train_idx], patients[val_idx]\n        train_data = df[df['Patient'].isin(train_p)]\n        val_data = df[df['Patient'].isin(val_p)]\n        \n        X_train = torch.tensor(train_data[features].values, dtype=torch.float32).to(CONFIG['device'])\n        y_train_ratio_scaled = torch.tensor(train_data['FVC_Ratio_Scaled'].values, dtype=torch.float32).unsqueeze(1).to(CONFIG['device'])\n        \n        X_val = torch.tensor(val_data[features].values, dtype=torch.float32).to(CONFIG['device'])\n        y_val_fvc = val_data['FVC'].values\n        val_baselines = val_data['Base_FVC_Raw'].values\n        \n        model = EnhancedQuantileMLP(len(features), CONFIG['quantiles']).to(CONFIG['device'])\n        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='max', factor=0.5, patience=20, verbose=False\n        )\n        \n        best_lll = -float('inf')\n        best_ratio_preds = None\n        patience_counter = 0\n        \n        for epoch in range(CONFIG['epochs']):\n            model.train()\n            optimizer.zero_grad()\n            preds_ratio_scaled = model(X_train)\n            \n            loss = quantile_loss(preds_ratio_scaled, y_train_ratio_scaled, CONFIG['quantiles'])\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            model.eval()\n            with torch.no_grad():\n                val_preds_ratio_scaled = model(X_val)\n                val_preds_ratio = ratio_scaler.inverse_transform(val_preds_ratio_scaled.cpu().numpy())\n                \n                metrics = calculate_metrics(y_val_fvc, val_preds_ratio, val_baselines)\n                lll = metrics['lll']\n                \n            scheduler.step(lll)\n            \n            if lll > best_lll:\n                best_lll = lll\n                best_ratio_preds = val_preds_ratio.copy()\n                patience_counter = 0\n                # üéØ SAVE MODEL WITH REQUESTED NAME\n                torch.save(model.state_dict(), f\"optimised_model_fold{fold+1}.pth\")\n            else:\n                patience_counter += 1\n                \n            if patience_counter >= CONFIG['patience']:\n                break\n        \n        oof_indices.extend(val_data.index.tolist())\n        oof_ratio_preds.append(best_ratio_preds)\n        oof_trues_fvc.extend(y_val_fvc)\n        oof_baselines.extend(val_baselines)\n        \n        fold_metrics = calculate_metrics(y_val_fvc, best_ratio_preds, val_baselines)\n        print(f\"\\nüìà FOLD {fold+1} RESULTS:\")\n        print(f\"  R¬≤:   {fold_metrics['r2']:.4f}\")\n        print(f\"  RMSE: {fold_metrics['rmse']:.2f} mL\")\n        print(f\"  LLL:  {fold_metrics['lll']:.4f}\")\n    \n    oof_ratio_preds = np.vstack(oof_ratio_preds)\n    oof_trues_fvc = np.array(oof_trues_fvc)\n    oof_baselines = np.array(oof_baselines)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üèÅ BASELINE RATIO PREDICTION RESULTS\")\n    print(\"=\"*80)\n    baseline_metrics = calculate_metrics(oof_trues_fvc, oof_ratio_preds, oof_baselines)\n    print(f\"R¬≤:   {baseline_metrics['r2']:.4f}   {'‚úÖ' if baseline_metrics['r2'] > 0.88 else '‚ùå'} (Target > 0.88)\")\n    print(f\"RMSE: {baseline_metrics['rmse']:.2f} mL {'‚úÖ' if baseline_metrics['rmse'] < 170 else '‚ùå'} (Target < 170)\")\n    print(f\"MAE:  {baseline_metrics['mae']:.2f} mL\")\n    print(f\"LLL:  {baseline_metrics['lll']:.4f}   {'‚úÖ' if baseline_metrics['lll'] > -6.64 else '‚ùå'} (Target > -6.64)\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üß™ OPTIONAL: SIGMA CALIBRATION\")\n    print(\"=\"*80)\n    \n    best_lll = baseline_metrics['lll']\n    best_factor = 1.0\n    \n    for scale in [0.95, 0.90, 0.85, 0.80, 0.75]:\n        calibrated = calibrate_sigma_ratio(oof_ratio_preds, scale)\n        metrics = calculate_metrics(oof_trues_fvc, calibrated, oof_baselines)\n        \n        improvement = \"‚úÖ\" if metrics['lll'] > best_lll else \"\"\n        print(f\"  œÉ√ó{scale:.2f} ‚Üí LLL: {metrics['lll']:.4f} (RMSE: {metrics['rmse']:.2f}) {improvement}\")\n        \n        if metrics['lll'] > best_lll:\n            best_lll = metrics['lll']\n            best_factor = scale\n    \n    if best_factor < 1.0:\n        final_preds = calibrate_sigma_ratio(oof_ratio_preds, best_factor)\n        final_metrics = calculate_metrics(oof_trues_fvc, final_preds, oof_baselines)\n        \n        print(\"\\n\" + \"=\"*80)\n        print(\"üèÜ FINAL RESULTS (With Optimal Sigma)\")\n        print(\"=\"*80)\n        print(f\"Best œÉ scale factor: {best_factor:.2f}\")\n        print(f\"\\nR¬≤:   {final_metrics['r2']:.4f}   {'‚úÖ' if final_metrics['r2'] > 0.88 else '‚ùå'} (Target > 0.88)\")\n        print(f\"RMSE: {final_metrics['rmse']:.2f} mL {'‚úÖ' if final_metrics['rmse'] < 170 else '‚ùå'} (Target < 170)\")\n        print(f\"MAE:  {final_metrics['mae']:.2f} mL\")\n        print(f\"LLL:  {final_metrics['lll']:.4f}   {'‚úÖ' if final_metrics['lll'] > -6.64 else '‚ùå'} (Target > -6.64)\")\n        \n        print(\"\\n\" + \"=\"*80)\n        print(\"üìä IMPROVEMENT OVER BASELINE\")\n        print(\"=\"*80)\n        print(f\"RMSE: {baseline_metrics['rmse']:.2f} ‚Üí {final_metrics['rmse']:.2f} ({final_metrics['rmse'] - baseline_metrics['rmse']:+.2f} mL)\")\n        print(f\"LLL:  {baseline_metrics['lll']:.4f} ‚Üí {final_metrics['lll']:.4f} ({final_metrics['lll'] - baseline_metrics['lll']:+.4f})\")\n    else:\n        print(\"\\n‚úÖ No sigma calibration needed - baseline predictions are optimal!\")\n    \n    print(\"=\"*80)\n\nif __name__ == \"__main__\":\n    train_ratio_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T12:15:16.215007Z","iopub.execute_input":"2025-11-28T12:15:16.215557Z","iopub.status.idle":"2025-11-28T12:15:22.796662Z","shell.execute_reply.started":"2025-11-28T12:15:16.215522Z","shell.execute_reply":"2025-11-28T12:15:22.795501Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Preprocessing Complete. Final Shape: (1549, 28)\n‚úÖ Features Used: 18\n\nüöÄ Training RATIO PREDICTION Model\nüìä Training on 1549 visits across 176 patients\n================================================================================\n\n================================================================================\nFOLD 1/5\n================================================================================\n\nüìà FOLD 1 RESULTS:\n  R¬≤:   0.9383\n  RMSE: 195.41 mL\n  LLL:  -6.4966\n\n================================================================================\nFOLD 2/5\n================================================================================\n\nüìà FOLD 2 RESULTS:\n  R¬≤:   0.9317\n  RMSE: 232.93 mL\n  LLL:  -6.8178\n\n================================================================================\nFOLD 3/5\n================================================================================\n\nüìà FOLD 3 RESULTS:\n  R¬≤:   0.8949\n  RMSE: 243.82 mL\n  LLL:  -6.8281\n\n================================================================================\nFOLD 4/5\n================================================================================\n\nüìà FOLD 4 RESULTS:\n  R¬≤:   0.9111\n  RMSE: 228.20 mL\n  LLL:  -6.6730\n\n================================================================================\nFOLD 5/5\n================================================================================\n\nüìà FOLD 5 RESULTS:\n  R¬≤:   0.9504\n  RMSE: 201.94 mL\n  LLL:  -6.6604\n\n================================================================================\nüèÅ BASELINE RATIO PREDICTION RESULTS\n================================================================================\nR¬≤:   0.9295   ‚úÖ (Target > 0.88)\nRMSE: 221.09 mL ‚ùå (Target < 170)\nMAE:  152.18 mL\nLLL:  -6.6942   ‚ùå (Target > -6.64)\n\n================================================================================\nüß™ OPTIONAL: SIGMA CALIBRATION\n================================================================================\n  œÉ√ó0.95 ‚Üí LLL: -6.6982 (RMSE: 221.09) \n  œÉ√ó0.90 ‚Üí LLL: -6.7053 (RMSE: 221.09) \n  œÉ√ó0.85 ‚Üí LLL: -6.7158 (RMSE: 221.09) \n  œÉ√ó0.80 ‚Üí LLL: -6.7306 (RMSE: 221.09) \n  œÉ√ó0.75 ‚Üí LLL: -6.7506 (RMSE: 221.09) \n\n‚úÖ No sigma calibration needed - baseline predictions are optimal!\n================================================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}