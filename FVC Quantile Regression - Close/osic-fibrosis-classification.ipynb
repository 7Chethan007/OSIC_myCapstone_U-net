{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Driven Early Prediction of Pulmonary Fibrosis Using Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T09:16:27.892768Z",
     "iopub.status.busy": "2025-11-28T09:16:27.892078Z",
     "iopub.status.idle": "2025-11-28T09:16:32.464549Z",
     "shell.execute_reply": "2025-11-28T09:16:32.463767Z",
     "shell.execute_reply.started": "2025-11-28T09:16:27.892743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing Complete. Final Shape: (1549, 23)\n",
      "âœ… Features Used: 16\n",
      "ðŸš€ Training Direct FVC Quantile Regression on 1549 visits.\n",
      "Features: ['Age', 'Base_FVC', 'Base_Percent', 'Relative_Weeks', 'lung_vol_ml', 'hu_mean', 'hu_std', 'hu_skew', 'hu_kurt', 'glcm_contrast', 'glcm_homogeneity', 'glcm_energy', 'glcm_correlation', 'Sex', 'Smk_Ex', 'Smk_Cur']\n",
      "Fold 1 Best | LLL: -6.8408\n",
      "Fold 2 Best | LLL: -6.9963\n",
      "Fold 3 Best | LLL: -6.8772\n",
      "Fold 4 Best | LLL: -6.9388\n",
      "Fold 5 Best | LLL: -6.8931\n",
      "\n",
      "==================================================\n",
      "ðŸ† FINAL DIRECT FVC QUANTILE RESULTS\n",
      "==================================================\n",
      "RÂ² (FVC Correlation) : 0.9049   (Target > 0.88)\n",
      "MSE (mLÂ²)            : 65878.0976\n",
      "RMSE (mL)            : 256.6673  (Target < 170)\n",
      "MAE (mL)             : 185.8179\n",
      "RMAE (Relative Error): 0.0691\n",
      "LLL (OSIC Metric)    : -6.9088   (Target > -6.64)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    \"lr\": 2e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 200,\n",
    "    \"n_folds\": 5,\n",
    "    \"quantiles\": [0.2, 0.5, 0.8], \n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"data_dir\": \"../input/osic-pulmonary-fibrosis-progression\",\n",
    "    # Point to your extracted features file\n",
    "    \"biomarker_path\": \"../input/feature-extraction-u-net-segmentation/master_dataset.csv\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA PREPROCESSING (ROBUST MERGE)\n",
    "# ==========================================\n",
    "def preprocess_data(config):\n",
    "    global TARGET_SCALER\n",
    "    \n",
    "    # 1. Load Clinical Data (Guarantees Sex, Age, Weeks exist)\n",
    "    clinical_df = pd.read_csv(f\"{config['data_dir']}/train.csv\")\n",
    "    \n",
    "    # 2. Load Biomarkers\n",
    "    biomarkers_df = pd.read_csv(config['biomarker_path'])\n",
    "    \n",
    "    # 3. Robust Merge Logic\n",
    "    # We only want the image features from the biomarkers file to avoid duplicates\n",
    "    image_features = [\n",
    "        'lung_vol_ml', 'hu_mean', 'hu_std', 'hu_skew', 'hu_kurt',\n",
    "        'glcm_contrast', 'glcm_homogeneity', 'glcm_energy', 'glcm_correlation'\n",
    "    ]\n",
    "    \n",
    "    # Filter biomarkers_df to only keep Patient + Image Features\n",
    "    # This prevents 'Sex_x', 'Sex_y' conflicts if columns repeat\n",
    "    cols_to_keep = ['Patient'] + [c for c in image_features if c in biomarkers_df.columns]\n",
    "    \n",
    "    # Remove duplicates in biomarkers (keep 1 row per patient)\n",
    "    biomarkers_clean = biomarkers_df[cols_to_keep].drop_duplicates(subset=['Patient'])\n",
    "    \n",
    "    # MERGE: Clinical (Left) + Biomarkers (Right)\n",
    "    train = clinical_df.merge(biomarkers_clean, on='Patient', how='inner')\n",
    "    \n",
    "    # 4. Feature Engineering (Baseline & Relative Weeks)\n",
    "    train['Weeks'] = train['Weeks'].astype(int)\n",
    "    train.sort_values(['Patient', 'Weeks'], inplace=True)\n",
    "    \n",
    "    baseline = train.groupby('Patient').first().reset_index()\n",
    "    baseline = baseline[['Patient', 'FVC', 'Percent']].rename(columns={'FVC': 'Base_FVC', 'Percent': 'Base_Percent'})\n",
    "    train = train.merge(baseline, on='Patient', how='left')\n",
    "    \n",
    "    base_weeks = train.groupby('Patient')['Weeks'].min().reset_index().rename(columns={'Weeks': 'Base_Week'})\n",
    "    train = train.merge(base_weeks, on='Patient', how='left')\n",
    "    train['Relative_Weeks'] = train['Weeks'] - train['Base_Week']\n",
    "    \n",
    "    # 5. Feature Scaling\n",
    "    scaler = RobustScaler()\n",
    "    # Dynamic check for available columns\n",
    "    available_img_feats = [c for c in image_features if c in train.columns]\n",
    "    \n",
    "    num_cols = ['Age', 'Base_FVC', 'Base_Percent', 'Relative_Weeks'] + available_img_feats\n",
    "    train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "    \n",
    "    # 6. Encoding (Now guaranteed to work)\n",
    "    train['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "    train['Smk_Ex'] = train['SmokingStatus'].apply(lambda x: 1 if x == 'Ex-smoker' else 0)\n",
    "    train['Smk_Cur'] = train['SmokingStatus'].apply(lambda x: 1 if x == 'Currently smokes' else 0)\n",
    "    \n",
    "    feature_cols = num_cols + ['Sex', 'Smk_Ex', 'Smk_Cur']\n",
    "    \n",
    "    # 7. Target Scaling\n",
    "    TARGET_SCALER.fit(train[['FVC']])\n",
    "    train['FVC_scaled'] = TARGET_SCALER.transform(train[['FVC']])\n",
    "    \n",
    "    print(f\"âœ… Preprocessing Complete. Final Shape: {train.shape}\")\n",
    "    print(f\"âœ… Features Used: {len(feature_cols)}\")\n",
    "    \n",
    "    return train, feature_cols\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL: QUANTILE MLP\n",
    "# ==========================================\n",
    "class QuantileMLP(nn.Module):\n",
    "    def __init__(self, input_dim, quantiles):\n",
    "        super().__init__()\n",
    "        hidden = 128\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden), nn.BatchNorm1d(hidden), nn.LeakyReLU(0.1), nn.Dropout(0.3),\n",
    "            nn.Linear(hidden, hidden), nn.BatchNorm1d(hidden), nn.LeakyReLU(0.1), nn.Dropout(0.3),\n",
    "            nn.Linear(hidden, len(quantiles))\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def quantile_loss(preds, target, quantiles):\n",
    "    \"\"\"Pinball Loss on SCALED targets.\"\"\"\n",
    "    assert not target.requires_grad\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i].unsqueeze(1)\n",
    "        loss = torch.max((q-1) * errors, q * errors)\n",
    "        losses.append(loss)\n",
    "    return torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "\n",
    "# ==========================================\n",
    "# 4. METRIC CALCULATION\n",
    "# ==========================================\n",
    "def calculate_metrics(y_true, q_preds_real):\n",
    "    \"\"\"\n",
    "    Calculates metrics on UNSCALED (Real) values.\n",
    "    \"\"\"\n",
    "    q20 = q_preds_real[:, 0]\n",
    "    q50 = q_preds_real[:, 1]\n",
    "    q80 = q_preds_real[:, 2]\n",
    "    \n",
    "    # Sigma (Uncertainty)\n",
    "    sigma = q80 - q20\n",
    "    sigma_clipped = np.maximum(sigma, 70)\n",
    "    \n",
    "    # LLL\n",
    "    delta = np.minimum(np.abs(y_true - q50), 1000)\n",
    "    lll = - (np.sqrt(2) * delta / sigma_clipped) - np.log(np.sqrt(2) * sigma_clipped)\n",
    "    \n",
    "    # Regression Metrics\n",
    "    mse = mean_squared_error(y_true, q50)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, q50)\n",
    "    r2 = r2_score(y_true, q50)\n",
    "    rmae = mae / (np.mean(np.abs(y_true)) + 1e-6)\n",
    "    \n",
    "    return np.mean(lll), mse, rmse, mae, rmae, r2\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAINING LOOP\n",
    "# ==========================================\n",
    "def train_model():\n",
    "    df, features = preprocess_data(CONFIG)\n",
    "    patients = df['Patient'].unique()\n",
    "    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=42)\n",
    "    \n",
    "    global_trues, global_preds = [], []\n",
    "    \n",
    "    print(f\"ðŸš€ Training Direct FVC Quantile Regression on {len(df)} visits.\")\n",
    "    print(f\"Features: {features}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(patients)):\n",
    "        train_p, val_p = patients[train_idx], patients[val_idx]\n",
    "        train_data = df[df['Patient'].isin(train_p)]\n",
    "        val_data = df[df['Patient'].isin(val_p)]\n",
    "        \n",
    "        # Train on SCALED FVC\n",
    "        X_train = torch.tensor(train_data[features].values, dtype=torch.float32).to(CONFIG['device'])\n",
    "        y_train_scaled = torch.tensor(train_data['FVC_scaled'].values, dtype=torch.float32).unsqueeze(1).to(CONFIG['device'])\n",
    "        \n",
    "        X_val = torch.tensor(val_data[features].values, dtype=torch.float32).to(CONFIG['device'])\n",
    "        \n",
    "        # Validation on RAW FVC (for final metrics)\n",
    "        y_val_real = val_data['FVC'].values\n",
    "        \n",
    "        model = QuantileMLP(len(features), CONFIG['quantiles']).to(CONFIG['device'])\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'], eta_min=1e-6)\n",
    "        \n",
    "        best_lll = -float('inf')\n",
    "        best_preds_real = None\n",
    "        \n",
    "        for epoch in range(CONFIG['epochs']):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds_scaled = model(X_train)\n",
    "            \n",
    "            # Loss on SCALED targets\n",
    "            loss = quantile_loss(preds_scaled, y_train_scaled, CONFIG['quantiles'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_preds_scaled = model(X_val)\n",
    "                \n",
    "                # UNSCALE Predictions for metrics\n",
    "                val_preds_real = TARGET_SCALER.inverse_transform(val_preds_scaled.cpu().numpy())\n",
    "                \n",
    "                lll, _, _, _, _, _ = calculate_metrics(y_val_real, val_preds_real)\n",
    "                \n",
    "            if lll > best_lll:\n",
    "                best_lll = lll\n",
    "                best_preds_real = val_preds_real\n",
    "                \n",
    "        print(f\"Fold {fold+1} Best | LLL: {best_lll:.4f}\")\n",
    "        \n",
    "        global_trues.extend(y_val_real)\n",
    "        global_preds.extend(best_preds_real)\n",
    "\n",
    "    # --- FINAL SCORE ---\n",
    "    g_true = np.array(global_trues)\n",
    "    g_pred = np.array(global_preds) \n",
    "    \n",
    "    lll, mse, rmse, mae, rmae, r2 = calculate_metrics(g_true, g_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ† FINAL DIRECT FVC QUANTILE RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"RÂ² (FVC Correlation) : {r2:.4f}   (Target > 0.88)\")\n",
    "    print(f\"MSE (mLÂ²)            : {mse:.4f}\")\n",
    "    print(f\"RMSE (mL)            : {rmse:.4f}  (Target < 170)\")\n",
    "    print(f\"MAE (mL)             : {mae:.4f}\")\n",
    "    print(f\"RMAE (Relative Error): {rmae:.4f}\")\n",
    "    print(f\"LLL (OSIC Metric)    : {lll:.4f}   (Target > -6.64)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1357052,
     "sourceId": 20604,
     "sourceType": "competition"
    },
    {
     "datasetId": 8852072,
     "sourceId": 13905913,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 516804,
     "modelInstanceId": 501638,
     "sourceId": 662983,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
